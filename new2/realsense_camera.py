#!/usr/bin/env python3
"""
RealSenseç›¸æœºç®¡ç†æ¨¡å—
æ”¯æŒRealSenseæ·±åº¦ç›¸æœºå’Œæ™®é€šæ‘„åƒå¤´
"""

import cv2 as cv
import numpy as np
from typing import Tuple, Optional, Dict, Any
import time

try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
except ImportError:
    REALSENSE_AVAILABLE = False
    print("âš ï¸ pyrealsense2 not available, using mock camera")

class RealSenseCamera:
    """
    RealSenseæ·±åº¦ç›¸æœºç®¡ç†ç±»
    """
    
    def __init__(self, width: int = 640, height: int = 480, fps: int = 30):
        """
        åˆå§‹åŒ–RealSenseç›¸æœº
        
        Args:
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            fps: å¸§ç‡
        """
        self.width = width
        self.height = height
        self.fps = fps
        
        # åˆå§‹åŒ–RealSenseç®¡é“
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        
        # é…ç½®æµ
        self.config.enable_stream(rs.stream.depth, width, height, rs.format.z16, fps)
        self.config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, fps)
        
        # æ·±åº¦å¯¹é½å™¨
        self.align = rs.align(rs.stream.color)
        
        # æ·±åº¦å¯è§†åŒ–
        self.depth_scale = None
        self.depth_visualizer = rs.colorizer()
        
        self.is_running = False
        
    def start(self) -> bool:
        """
        å¯åŠ¨ç›¸æœº
        
        Returns:
            bool: å¯åŠ¨æ˜¯å¦æˆåŠŸ
        """
        try:
            # å¯åŠ¨ç®¡é“
            profile = self.pipeline.start(self.config)
            
            # è·å–æ·±åº¦æ¯”ä¾‹
            depth_sensor = profile.get_device().first_depth_sensor()
            self.depth_scale = depth_sensor.get_depth_scale()
            
            self.is_running = True
            print(f"âœ… RealSenseç›¸æœºå¯åŠ¨æˆåŠŸ")
            print(f"   åˆ†è¾¨ç‡: {self.width}x{self.height}")
            print(f"   å¸§ç‡: {self.fps}")
            print(f"   æ·±åº¦æ¯”ä¾‹: {self.depth_scale}")
            
            return True
            
        except Exception as e:
            print(f"âŒ RealSenseç›¸æœºå¯åŠ¨å¤±è´¥: {e}")
            return False
    
    def get_frames(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """
        è·å–æ·±åº¦å¸§å’Œå½©è‰²å¸§
        
        Returns:
            Tuple[æ·±åº¦å¸§, å½©è‰²å¸§]: æ·±åº¦å›¾(ç±³)å’Œå½©è‰²å›¾
        """
        if not self.is_running:
            return None, None
            
        try:
            # ç­‰å¾…å¸§
            frames = self.pipeline.wait_for_frames()
            
            # å¯¹é½æ·±åº¦å¸§åˆ°å½©è‰²å¸§
            aligned_frames = self.align.process(frames)
            
            # è·å–å¯¹é½åçš„æ·±åº¦å¸§å’Œå½©è‰²å¸§
            depth_frame = aligned_frames.get_depth_frame()
            color_frame = aligned_frames.get_color_frame()
            
            if not depth_frame or not color_frame:
                return None, None
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            depth_image = np.asanyarray(depth_frame.get_data())
            color_image = np.asanyarray(color_frame.get_data())
            
            # è½¬æ¢æ·±åº¦å•ä½ä¸ºç±³
            if self.depth_scale:
                depth_image = depth_image.astype(np.float32) * self.depth_scale
            
            return depth_image, color_image
            
        except Exception as e:
            print(f"âŒ è·å–å¸§å¤±è´¥: {e}")
            return None, None
    
    def create_depth_visualization(self, depth_image: np.ndarray) -> np.ndarray:
        """
        åˆ›å»ºæ·±åº¦å›¾å¯è§†åŒ–
        
        Args:
            depth_image: æ·±åº¦å›¾åƒ(ç±³)
            
        Returns:
            np.ndarray: å½©è‰²æ·±åº¦å›¾
        """
        if depth_image is None:
            return np.zeros((self.height, self.width, 3), dtype=np.uint8)
        
        # è½¬æ¢ä¸º16ä½æ·±åº¦å›¾ç”¨äºå¯è§†åŒ–
        if self.depth_scale and self.depth_scale > 0:
            depth_16bit = (depth_image / self.depth_scale).astype(np.uint16)
        else:
            # å¦‚æœæ²¡æœ‰æ·±åº¦æ¯”ä¾‹ï¼Œç›´æ¥ä½¿ç”¨æ·±åº¦å€¼
            depth_16bit = (depth_image * 1000).astype(np.uint16)  # è½¬æ¢ä¸ºæ¯«ç±³
        
        # ä½¿ç”¨OpenCVçš„é¢œè‰²æ˜ å°„è¿›è¡Œå¯è§†åŒ–
        # å°†æ·±åº¦å€¼å½’ä¸€åŒ–åˆ°0-255èŒƒå›´
        depth_normalized = cv.normalize(depth_16bit, None, 0, 255, cv.NORM_MINMAX, dtype=cv.CV_8U)
        
        # åº”ç”¨é¢œè‰²æ˜ å°„
        colorized_image = cv.applyColorMap(depth_normalized, cv.COLORMAP_JET)
        
        return colorized_image
    
    def get_camera_info(self) -> Dict[str, Any]:
        """
        è·å–ç›¸æœºä¿¡æ¯
        
        Returns:
            Dict: ç›¸æœºä¿¡æ¯
        """
        return {
            'type': 'RealSense',
            'width': self.width,
            'height': self.height,
            'fps': self.fps,
            'depth_scale': self.depth_scale,
            'is_running': self.is_running
        }
    
    def is_available(self) -> bool:
        """
        æ£€æŸ¥ç›¸æœºæ˜¯å¦å¯ç”¨
        
        Returns:
            bool: ç›¸æœºæ˜¯å¦å¯ç”¨
        """
        return self.is_running
    
    def cleanup(self):
        """
        æ¸…ç†èµ„æº
        """
        if self.is_running:
            self.pipeline.stop()
            self.is_running = False
            print("âœ… RealSenseç›¸æœºå·²åœæ­¢")


class MockCamera:
    """
    æ¨¡æ‹Ÿç›¸æœºç±»ï¼ˆä½¿ç”¨æ™®é€šæ‘„åƒå¤´ï¼‰
    """
    
    def __init__(self, camera_index: int = 0, width: int = 640, height: int = 480):
        """
        åˆå§‹åŒ–æ¨¡æ‹Ÿç›¸æœº
        
        Args:
            camera_index: æ‘„åƒå¤´ç´¢å¼•
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
        """
        self.camera_index = camera_index
        self.width = width
        self.height = height
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        self.cap = cv.VideoCapture(camera_index)
        
        if self.cap.isOpened():
            # è®¾ç½®åˆ†è¾¨ç‡
            self.cap.set(cv.CAP_PROP_FRAME_WIDTH, width)
            self.cap.set(cv.CAP_PROP_FRAME_HEIGHT, height)
            
            # è®¾ç½®å¸§ç‡
            self.cap.set(cv.CAP_PROP_FPS, 30)
            
            self.is_running = True
            print(f"âœ… æ¨¡æ‹Ÿç›¸æœºå¯åŠ¨æˆåŠŸ (æ‘„åƒå¤´ {camera_index})")
            print(f"   åˆ†è¾¨ç‡: {width}x{height}")
        else:
            self.is_running = False
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_index}")
    
    def get_frames(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """
        è·å–æ·±åº¦å¸§å’Œå½©è‰²å¸§ï¼ˆæ¨¡æ‹Ÿç‰ˆæœ¬ï¼‰
        
        Returns:
            Tuple[æ·±åº¦å¸§, å½©è‰²å¸§]: æ¨¡æ‹Ÿæ·±åº¦å›¾å’Œå½©è‰²å›¾
        """
        if not self.is_running:
            return None, None
            
        ret, color_image = self.cap.read()
        if not ret:
            return None, None
        
        # è°ƒæ•´å›¾åƒå¤§å°
        color_image = cv.resize(color_image, (self.width, self.height))
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ·±åº¦å›¾ï¼ˆåŸºäºå›¾åƒäº®åº¦ï¼‰
        gray = cv.cvtColor(color_image, cv.COLOR_BGR2GRAY)
        
        # ç®€å•çš„æ·±åº¦æ¨¡æ‹Ÿï¼šåŸºäºäº®åº¦åæ¯”
        # è¾ƒæš—çš„åŒºåŸŸå‡è®¾æ›´è¿‘ï¼Œè¾ƒäº®çš„åŒºåŸŸå‡è®¾æ›´è¿œ
        depth_image = (255 - gray).astype(np.float32) / 255.0
        
        # æ·»åŠ ä¸€äº›éšæœºå™ªå£°ä½¿æ·±åº¦å›¾æ›´çœŸå®
        noise = np.random.normal(0, 0.05, depth_image.shape)
        depth_image = np.clip(depth_image + noise, 0.1, 2.0)
        
        return depth_image, color_image
    
    def create_depth_visualization(self, depth_image: np.ndarray) -> np.ndarray:
        """
        åˆ›å»ºæ·±åº¦å›¾å¯è§†åŒ–ï¼ˆæ¨¡æ‹Ÿç‰ˆæœ¬ï¼‰
        
        Args:
            depth_image: æ·±åº¦å›¾åƒ(ç±³)
            
        Returns:
            np.ndarray: å½©è‰²æ·±åº¦å›¾
        """
        if depth_image is None:
            return np.zeros((self.height, self.width, 3), dtype=np.uint8)
        
        # å°†æ·±åº¦å›¾è½¬æ¢ä¸º0-255èŒƒå›´
        if depth_image.max() > depth_image.min():
            depth_normalized = ((depth_image - depth_image.min()) / 
                               (depth_image.max() - depth_image.min()) * 255).astype(np.uint8)
        else:
            depth_normalized = np.zeros_like(depth_image, dtype=np.uint8)
        
        # åº”ç”¨é¢œè‰²æ˜ å°„
        depth_colored = cv.applyColorMap(depth_normalized, cv.COLORMAP_JET)
        
        return depth_colored
    
    def get_camera_info(self) -> Dict[str, Any]:
        """
        è·å–ç›¸æœºä¿¡æ¯
        
        Returns:
            Dict: ç›¸æœºä¿¡æ¯
        """
        return {
            'type': 'Mock',
            'camera_index': self.camera_index,
            'width': self.width,
            'height': self.height,
            'is_running': self.is_running
        }
    
    def is_available(self) -> bool:
        """
        æ£€æŸ¥ç›¸æœºæ˜¯å¦å¯ç”¨
        
        Returns:
            bool: ç›¸æœºæ˜¯å¦å¯ç”¨
        """
        return self.is_running and self.cap.isOpened()
    
    def cleanup(self):
        """
        æ¸…ç†èµ„æº
        """
        if self.cap.isOpened():
            self.cap.release()
            self.is_running = False
            print("âœ… æ¨¡æ‹Ÿç›¸æœºå·²åœæ­¢")


def create_camera(camera_type: str = "auto", **kwargs) -> Any:
    """
    ç›¸æœºå·¥å‚å‡½æ•°
    
    Args:
        camera_type: ç›¸æœºç±»å‹ ("realsense", "mock", "auto")
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        ç›¸æœºå¯¹è±¡
    """
    if camera_type == "realsense":
        if not REALSENSE_AVAILABLE:
            print("âš ï¸ RealSenseä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç›¸æœº")
            return MockCamera(**kwargs)
        
        camera = RealSenseCamera(**kwargs)
        if camera.start():
            return camera
        else:
            print("âš ï¸ RealSenseå¯åŠ¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç›¸æœº")
            return MockCamera(**kwargs)
    
    elif camera_type == "mock":
        return MockCamera(**kwargs)
    
    elif camera_type == "auto":
        # è‡ªåŠ¨é€‰æ‹©ï¼šä¼˜å…ˆå°è¯•RealSense
        if REALSENSE_AVAILABLE:
            camera = RealSenseCamera(**kwargs)
            if camera.start():
                return camera
        
        # RealSenseä¸å¯ç”¨æˆ–å¯åŠ¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç›¸æœº
        print("ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°æ¨¡æ‹Ÿç›¸æœº")
        return MockCamera(**kwargs)
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ç›¸æœºç±»å‹: {camera_type}")


def main():
    """
    æµ‹è¯•ç›¸æœºåŠŸèƒ½
    """
    print("ğŸš€ æµ‹è¯•ç›¸æœºåŠŸèƒ½...")
    
    # åˆ›å»ºç›¸æœº
    camera = create_camera("auto")
    
    if not camera.is_available():
        print("âŒ ç›¸æœºä¸å¯ç”¨")
        return
    
    print(f"ğŸ“· ç›¸æœºä¿¡æ¯: {camera.get_camera_info()}")
    
    try:
        frame_count = 0
        while frame_count < 100:  # æµ‹è¯•100å¸§
            depth_frame, color_frame = camera.get_frames()
            
            if depth_frame is not None and color_frame is not None:
                # æ˜¾ç¤ºå½©è‰²å›¾
                cv.imshow('Color Frame', color_frame)
                
                # æ˜¾ç¤ºæ·±åº¦å›¾
                depth_vis = camera.create_depth_visualization(depth_frame)
                cv.imshow('Depth Frame', depth_vis)
                
                frame_count += 1
                if frame_count % 10 == 0:
                    print(f"å¤„ç†å¸§: {frame_count}")
                
                # æŒ‰'q'é€€å‡º
                if cv.waitKey(1) & 0xFF == ord('q'):
                    break
            else:
                print("âŒ æ— æ³•è·å–å¸§")
                break
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
    
    finally:
        camera.cleanup()
        cv.destroyAllWindows()
        print("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
