#!/usr/bin/env python3
"""
YOLOv8åˆ†å‰²éšœç¢ç‰©æ£€æµ‹æ¨¡å—
ä½¿ç”¨YOLOv8-segè¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼Œè¾…åŠ©ç”Ÿæˆéšœç¢ç‰©æ©è†œ
"""

import cv2 as cv
import numpy as np
from typing import List, Tuple, Optional, Dict, Any
import time

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("âš ï¸ ultralytics not available, YOLOv8-segåŠŸèƒ½ä¸å¯ç”¨")

class YOLOObstacleDetector:
    """
    YOLOv8åˆ†å‰²éšœç¢ç‰©æ£€æµ‹å™¨
    ä½¿ç”¨YOLOv8-segè¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼Œè¯†åˆ«å’Œåˆ†ç¦»éšœç¢ç‰©
    """
    
    def __init__(self, 
                 model_path: str = "yolov8n-seg.pt",
                 confidence_threshold: float = 0.5,
                 device: str = "auto"):
        """
        åˆå§‹åŒ–YOLOv8éšœç¢ç‰©æ£€æµ‹å™¨
        
        Args:
            model_path: YOLOv8åˆ†å‰²æ¨¡å‹è·¯å¾„
            confidence_threshold: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
            device: è¿è¡Œè®¾å¤‡ ("cpu", "cuda", "auto")
        """
        self.model_path = model_path
        self.confidence_threshold = confidence_threshold
        self.device = device
        
        # éšœç¢ç‰©ç±»åˆ«ï¼ˆä½¿ç”¨YOLOv8æ¨¡å‹è‡ªå¸¦çš„ç±»åˆ«åç§°ï¼‰
        # è¿™äº›æ˜¯COCOæ•°æ®é›†çš„80ä¸ªç±»åˆ«ï¼ŒYOLOv8ä¼šè‡ªåŠ¨è¯†åˆ«
        self.obstacle_class_names = {
            # å®¶å…·ç±»
            'chair', 'couch', 'bed', 'dining table', 'toilet',
            'tv', 'laptop', 'mouse', 'remote', 'keyboard',
            'cell phone', 'microwave', 'oven', 'toaster',
            'sink', 'refrigerator', 'book', 'clock', 'vase',
            'scissors', 'teddy bear', 'hair drier', 'toothbrush',
            
            # äº¤é€šå·¥å…·ç±»
            'car', 'motorcycle', 'airplane', 'bus', 'train',
            'truck', 'boat', 'bicycle',
            
            # å…¶ä»–ç‰©ä½“
            'bottle', 'wine glass', 'cup', 'fork', 'knife',
            'spoon', 'bowl', 'banana', 'apple', 'sandwich',
            'orange', 'broccoli', 'carrot', 'hot dog',
            'pizza', 'donut', 'cake',
            
            # è¿åŠ¨ç”¨å“
            'sports ball', 'tennis racket',
        }
        
        # æ‰‹éƒ¨ç›¸å…³ç±»åˆ«ï¼ˆéœ€è¦æ’é™¤ï¼‰
        self.hand_related_class_names = {
            'person',  # äººä½“ï¼ŒåŒ…å«æ‰‹éƒ¨
        }
        
        self.model = None
        self.is_initialized = False
        
        # æ€§èƒ½ç»Ÿè®¡
        self.inference_times = []
        self.max_inference_time = 0.1  # æœ€å¤§æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
        
        if YOLO_AVAILABLE:
            self._initialize_model()
        else:
            print("âŒ YOLOv8ä¸å¯ç”¨ï¼Œè¯·å®‰è£…ultralytics: pip install ultralytics")
    
    def _initialize_model(self):
        """
        åˆå§‹åŒ–YOLOv8æ¨¡å‹
        """
        try:
            print(f"ğŸ”„ åŠ è½½YOLOv8åˆ†å‰²æ¨¡å‹: {self.model_path}")
            self.model = YOLO(self.model_path)
            
            # è®¾ç½®è®¾å¤‡
            if self.device == "auto":
                self.device = "cuda" if self.model.device.type == "cuda" else "cpu"
            
            print(f"âœ… YOLOv8æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   è®¾å¤‡: {self.device}")
            print(f"   ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold}")
            print(f"   éšœç¢ç‰©ç±»åˆ«æ•°: {len(self.obstacle_class_names)}")
            print(f"   æ¨¡å‹è‡ªå¸¦ç±»åˆ«: {len(self.model.names)} ä¸ª")
            
            # æ˜¾ç¤ºæ¨¡å‹æ”¯æŒçš„æ‰€æœ‰ç±»åˆ«
            print(f"   æ¨¡å‹æ”¯æŒçš„ç±»åˆ«: {list(self.model.names.values())}")
            
            self.is_initialized = True
            
        except Exception as e:
            print(f"âŒ YOLOv8æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.is_initialized = False
    
    def detect_obstacles(self, 
                        image: np.ndarray, 
                        hand_landmarks_3d: Optional[List] = None) -> Dict[str, Any]:
        """
        æ£€æµ‹å›¾åƒä¸­çš„éšœç¢ç‰©
        
        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            hand_landmarks_3d: æ‰‹éƒ¨å…³é”®ç‚¹3Dåæ ‡åˆ—è¡¨
            
        Returns:
            Dict: æ£€æµ‹ç»“æœ
        """
        if not self.is_initialized:
            return self._get_empty_result()
        
        start_time = time.time()
        
        try:
            # YOLOv8æ¨ç†
            results = self.model(image, 
                               conf=self.confidence_threshold,
                               device=self.device,
                               verbose=False)
            
            inference_time = time.time() - start_time
            self.inference_times.append(inference_time)
            
            # ä¿æŒæœ€è¿‘100æ¬¡çš„æ¨ç†æ—¶é—´
            if len(self.inference_times) > 100:
                self.inference_times = self.inference_times[-100:]
            
            # å¤„ç†æ£€æµ‹ç»“æœ
            detection_result = self._process_detection_results(results[0], image.shape)
            
            # ç”Ÿæˆéšœç¢ç‰©æ©è†œ
            obstacle_mask = self._generate_obstacle_mask(
                detection_result, image.shape, hand_landmarks_3d
            )
            
            detection_result.update({
                'obstacle_mask': obstacle_mask,
                'inference_time': inference_time,
                'fps': 1.0 / inference_time if inference_time > 0 else 0
            })
            
            return detection_result
            
        except Exception as e:
            print(f"âŒ YOLOv8æ¨ç†å¤±è´¥: {e}")
            return self._get_empty_result()
    
    def _process_detection_results(self, result, image_shape: Tuple[int, int, int]) -> Dict[str, Any]:
        """
        å¤„ç†YOLOv8æ£€æµ‹ç»“æœ
        
        Args:
            result: YOLOv8æ£€æµ‹ç»“æœ
            image_shape: å›¾åƒå½¢çŠ¶ (height, width, channels)
            
        Returns:
            Dict: å¤„ç†åçš„æ£€æµ‹ç»“æœ
        """
        height, width = image_shape[:2]
        
        detection_result = {
            'obstacles': [],
            'hand_regions': [],
            'obstacle_count': 0,
            'hand_region_count': 0,
            'total_detections': 0
        }
        
        if result.masks is None:
            return detection_result
        
        # å¤„ç†æ¯ä¸ªæ£€æµ‹ç»“æœ
        for i, (box, mask, conf, cls) in enumerate(zip(
            result.boxes.xyxy.cpu().numpy(),
            result.masks.data.cpu().numpy(),
            result.boxes.conf.cpu().numpy(),
            result.boxes.cls.cpu().numpy()
        )):
            class_id = int(cls)
            class_name = result.names[class_id]
            confidence = float(conf)
            
            # è°ƒæ•´æ©è†œå¤§å°åˆ°åŸå›¾å°ºå¯¸
            mask_resized = cv.resize(mask, (width, height))
            mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255
            
            detection_info = {
                'id': i,
                'class_id': class_id,
                'class_name': class_name,
                'confidence': confidence,
                'bbox': box.tolist(),
                'mask': mask_binary,
                'area': np.sum(mask_binary > 0)
            }
            
            # åˆ†ç±»ä¸ºéšœç¢ç‰©æˆ–æ‰‹éƒ¨åŒºåŸŸ
            if class_name in self.obstacle_class_names:
                detection_result['obstacles'].append(detection_info)
                detection_result['obstacle_count'] += 1
            elif class_name in self.hand_related_class_names:
                detection_result['hand_regions'].append(detection_info)
                detection_result['hand_region_count'] += 1
            
            detection_result['total_detections'] += 1
        
        return detection_result
    
    def _generate_obstacle_mask(self, 
                               detection_result: Dict[str, Any],
                               image_shape: Tuple[int, int, int],
                               hand_landmarks_3d: Optional[List] = None) -> np.ndarray:
        """
        ç”Ÿæˆéšœç¢ç‰©æ©è†œï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼Œç¡®ä¿ä¸æ·±åº¦å›¾å¯¹é½ï¼‰
        
        Args:
            detection_result: æ£€æµ‹ç»“æœ
            image_shape: å›¾åƒå½¢çŠ¶
            hand_landmarks_3d: æ‰‹éƒ¨å…³é”®ç‚¹3Dåæ ‡
            
        Returns:
            np.ndarray: éšœç¢ç‰©æ©è†œ
        """
        height, width = image_shape[:2]
        obstacle_mask = np.zeros((height, width), dtype=np.uint8)
        
        # åˆå¹¶æ‰€æœ‰éšœç¢ç‰©æ©è†œ
        for obstacle in detection_result['obstacles']:
            mask = obstacle['mask']
            
            # ç¡®ä¿æ©è†œå°ºå¯¸ä¸å›¾åƒå°ºå¯¸ä¸€è‡´
            if mask.shape != (height, width):
                mask = cv.resize(mask, (width, height))
            
            # äºŒå€¼åŒ–æ©è†œ
            mask_binary = (mask > 128).astype(np.uint8) * 255
            obstacle_mask = cv.bitwise_or(obstacle_mask, mask_binary)
        
        # æ’é™¤æ‰‹éƒ¨åŒºåŸŸ
        obstacle_mask = self._exclude_hand_regions(
            obstacle_mask, detection_result['hand_regions'], hand_landmarks_3d
        )
        
        # åå¤„ç†ï¼šå™ªå£°è¿‡æ»¤å’Œå½¢æ€å­¦æ“ä½œ
        obstacle_mask = self._post_process_mask(obstacle_mask)
        
        return obstacle_mask
    
    def _exclude_hand_regions(self, 
                             obstacle_mask: np.ndarray,
                             hand_regions: List[Dict],
                             hand_landmarks_3d: Optional[List] = None) -> np.ndarray:
        """
        ä»éšœç¢ç‰©æ©è†œä¸­æ’é™¤æ‰‹éƒ¨åŒºåŸŸï¼ˆè°ƒè¯•ç‰ˆæœ¬ï¼‰
        
        Args:
            obstacle_mask: åŸå§‹éšœç¢ç‰©æ©è†œ
            hand_regions: æ‰‹éƒ¨åŒºåŸŸæ£€æµ‹ç»“æœ
            hand_landmarks_3d: æ‰‹éƒ¨å…³é”®ç‚¹3Dåæ ‡
            
        Returns:
            np.ndarray: æ’é™¤æ‰‹éƒ¨åŒºåŸŸåçš„æ©è†œ
        """
        result_mask = obstacle_mask.copy()
        original_pixels = np.sum(obstacle_mask > 0)
        
        # æ’é™¤YOLOv8æ£€æµ‹åˆ°çš„æ‰‹éƒ¨åŒºåŸŸ
        for hand_region in hand_regions:
            hand_mask = hand_region['mask']
            # è†¨èƒ€æ‰‹éƒ¨åŒºåŸŸä»¥ç¡®ä¿å®Œå…¨æ’é™¤
            kernel = np.ones((15, 15), np.uint8)
            hand_mask_dilated = cv.dilate(hand_mask, kernel, iterations=1)
            result_mask = cv.bitwise_and(result_mask, cv.bitwise_not(hand_mask_dilated))
        
        # æ’é™¤MediaPipeæ£€æµ‹åˆ°çš„æ‰‹éƒ¨å…³é”®ç‚¹åŒºåŸŸï¼ˆå‡å°‘è†¨èƒ€ï¼Œé¿å…è¿‡åº¦æ’é™¤ï¼‰
        if hand_landmarks_3d:
            hand_landmark_mask = self._create_hand_landmark_mask(
                hand_landmarks_3d, obstacle_mask.shape
            )
            result_mask = cv.bitwise_and(result_mask, cv.bitwise_not(hand_landmark_mask))
        
        final_pixels = np.sum(result_mask > 0)
        excluded_pixels = original_pixels - final_pixels
        
        # è°ƒè¯•ä¿¡æ¯
        if excluded_pixels > 0:
            print(f"ğŸ” æ‰‹éƒ¨åŒºåŸŸæ’é™¤: {excluded_pixels} åƒç´ è¢«æ’é™¤")
        
        return result_mask
    
    def _create_hand_landmark_mask(self, 
                                  hand_landmarks_3d: List,
                                  mask_shape: Tuple[int, int]) -> np.ndarray:
        """
        åŸºäºæ‰‹éƒ¨å…³é”®ç‚¹åˆ›å»ºæ‰‹éƒ¨åŒºåŸŸæ©è†œï¼ˆå‡å°‘è†¨èƒ€ï¼Œé¿å…è¿‡åº¦æ’é™¤ï¼‰
        
        Args:
            hand_landmarks_3d: æ‰‹éƒ¨å…³é”®ç‚¹3Dåæ ‡åˆ—è¡¨
            mask_shape: æ©è†œå½¢çŠ¶
            
        Returns:
            np.ndarray: æ‰‹éƒ¨åŒºåŸŸæ©è†œ
        """
        height, width = mask_shape
        hand_mask = np.zeros((height, width), dtype=np.uint8)
        
        for landmark in hand_landmarks_3d:
            if len(landmark) >= 2 and landmark[2] > 0:  # æœ‰æ•ˆæ·±åº¦
                x, y = int(landmark[0]), int(landmark[1])
                if 0 <= x < width and 0 <= y < height:
                    # ä¸ºæ¯ä¸ªå…³é”®ç‚¹åˆ›å»ºè¾ƒå°çš„è†¨èƒ€åŒºåŸŸ
                    cv.circle(hand_mask, (x, y), 10, 255, -1)  # å‡å°‘åŠå¾„ä»20åˆ°10
        
        # å‡å°‘è†¨èƒ€ä»¥ç¡®ä¿ä¸ä¼šè¿‡åº¦æ’é™¤éšœç¢ç‰©
        kernel = np.ones((10, 10), np.uint8)  # å‡å°‘æ ¸å¤§å°ä»25åˆ°10
        hand_mask = cv.dilate(hand_mask, kernel, iterations=1)
        
        return hand_mask
    
    def _post_process_mask(self, mask: np.ndarray) -> np.ndarray:
        """
        æ©è†œåå¤„ç†ï¼šå™ªå£°è¿‡æ»¤å’Œå½¢æ€å­¦æ“ä½œ
        
        Args:
            mask: åŸå§‹æ©è†œ
            
        Returns:
            np.ndarray: å¤„ç†åçš„æ©è†œ
        """
        # ç§»é™¤å°çš„å™ªå£°åŒºåŸŸ
        kernel_small = np.ones((3, 3), np.uint8)
        mask = cv.morphologyEx(mask, cv.MORPH_OPEN, kernel_small)
        
        # å¡«å……å°çš„ç©ºæ´
        kernel_medium = np.ones((5, 5), np.uint8)
        mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel_medium)
        
        return mask
    
    def _get_empty_result(self) -> Dict[str, Any]:
        """
        è·å–ç©ºçš„æ£€æµ‹ç»“æœ
        
        Returns:
            Dict: ç©ºç»“æœ
        """
        return {
            'obstacles': [],
            'hand_regions': [],
            'obstacle_count': 0,
            'hand_region_count': 0,
            'total_detections': 0,
            'obstacle_mask': np.zeros((480, 640), dtype=np.uint8),
            'inference_time': 0.0,
            'fps': 0.0
        }
    
    def get_performance_stats(self) -> Dict[str, float]:
        """
        è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: æ€§èƒ½ç»Ÿè®¡
        """
        if not self.inference_times:
            return {'avg_inference_time': 0.0, 'avg_fps': 0.0, 'max_inference_time': 0.0}
        
        avg_time = np.mean(self.inference_times)
        avg_fps = 1.0 / avg_time if avg_time > 0 else 0.0
        max_time = np.max(self.inference_times)
        
        return {
            'avg_inference_time': avg_time,
            'avg_fps': avg_fps,
            'max_inference_time': max_time,
            'total_inferences': len(self.inference_times)
        }
    
    def visualize_detection(self, 
                           image: np.ndarray, 
                           detection_result: Dict[str, Any]) -> np.ndarray:
        """
        å¯è§†åŒ–æ£€æµ‹ç»“æœ
        
        Args:
            image: åŸå§‹å›¾åƒ
            detection_result: æ£€æµ‹ç»“æœ
            
        Returns:
            np.ndarray: å¯è§†åŒ–å›¾åƒ
        """
        vis_image = image.copy()
        
        # ç»˜åˆ¶éšœç¢ç‰©
        for obstacle in detection_result['obstacles']:
            bbox = obstacle['bbox']
            class_name = obstacle['class_name']
            confidence = obstacle['confidence']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            x1, y1, x2, y2 = map(int, bbox)
            cv.rectangle(vis_image, (x1, y1), (x2, y2), (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            cv.putText(vis_image, label, (x1, y1 - 10), 
                      cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        
        # ç»˜åˆ¶æ‰‹éƒ¨åŒºåŸŸ
        for hand_region in detection_result['hand_regions']:
            bbox = hand_region['bbox']
            class_name = hand_region['class_name']
            confidence = hand_region['confidence']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            x1, y1, x2, y2 = map(int, bbox)
            cv.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            cv.putText(vis_image, label, (x1, y1 - 10), 
                      cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_text = [
            f"Obstacles: {detection_result['obstacle_count']}",
            f"Hand Regions: {detection_result['hand_region_count']}",
            f"FPS: {detection_result['fps']:.1f}"
        ]
        
        for i, text in enumerate(stats_text):
            cv.putText(vis_image, text, (10, 30 + i * 25), 
                      cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return vis_image
    
    def cleanup(self):
        """
        æ¸…ç†èµ„æº
        """
        if self.model is not None:
            del self.model
            self.model = None
        self.is_initialized = False
        print("âœ… YOLOv8éšœç¢ç‰©æ£€æµ‹å™¨å·²æ¸…ç†")


def main():
    """
    æµ‹è¯•YOLOv8éšœç¢ç‰©æ£€æµ‹å™¨
    """
    print("ğŸš€ æµ‹è¯•YOLOv8éšœç¢ç‰©æ£€æµ‹å™¨...")
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = YOLOObstacleDetector(
        model_path="yolov8n-seg.pt",
        confidence_threshold=0.5
    )
    
    if not detector.is_initialized:
        print("âŒ æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
        return
    
    # æµ‹è¯•å›¾åƒï¼ˆä½¿ç”¨æ‘„åƒå¤´æˆ–æµ‹è¯•å›¾åƒï¼‰
    cap = cv.VideoCapture(0)
    
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return
    
    try:
        frame_count = 0
        while frame_count < 100:  # æµ‹è¯•100å¸§
            ret, frame = cap.read()
            if not ret:
                break
            
            # æ£€æµ‹éšœç¢ç‰©
            detection_result = detector.detect_obstacles(frame)
            
            # å¯è§†åŒ–ç»“æœ
            vis_frame = detector.visualize_detection(frame, detection_result)
            
            # æ˜¾ç¤ºéšœç¢ç‰©æ©è†œ
            obstacle_mask = detection_result['obstacle_mask']
            mask_colored = cv.applyColorMap(obstacle_mask, cv.COLORMAP_JET)
            
            # æ˜¾ç¤ºç»“æœ
            cv.imshow('YOLOv8 Obstacle Detection', vis_frame)
            cv.imshow('Obstacle Mask', mask_colored)
            
            frame_count += 1
            if frame_count % 10 == 0:
                stats = detector.get_performance_stats()
                print(f"å¸§ {frame_count}: {stats['avg_fps']:.1f} FPS")
            
            # æŒ‰'q'é€€å‡º
            if cv.waitKey(1) & 0xFF == ord('q'):
                break
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
    
    finally:
        cap.release()
        cv.destroyAllWindows()
        detector.cleanup()
        print("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
